{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b837670e",
   "metadata": {},
   "source": [
    "## Object criticality for better and safer navigation\n",
    "\n",
    "Main jupter; execute this to get the data; the other jupyter is to extract results and do some analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa478e",
   "metadata": {},
   "source": [
    "*What you need*\n",
    "\n",
    "* nuScenes dataset\n",
    "* mmdetection3d if you want to re-run the detectors against nuScenes\n",
    "* otherwise, just download the file we provide\n",
    "* our directories with the modified nuScenes-devkit library\n",
    "* conda environment, see yaml file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab89cccc",
   "metadata": {},
   "source": [
    "**Execute the object detectors**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67274a3b",
   "metadata": {},
   "source": [
    "First, you need to execute mmdetection3d models on nuScenes to compute all the Bounding Boxes and object attributes. Models are downloaded from mmdetection3d model zoo and typically stored in folder mmdetection3d/models/ . \n",
    "\n",
    "So you just need to launch python commands from mmdetection3d main folder. Results are saved in ./tmp with a default name. See below for model name, github to downlad it, weights file used, shell command, ... \n",
    "\n",
    "- SECFPN https://github.com/open-mmlab/mmdetection3d/tree/main/configs/ssn\n",
    "  - hv_pointpillars_regnet-400mf_secfpn_sbn-all_4x8_2x_nus-3d_20200620_230334-53044f32.pth\n",
    "\n",
    "    *run using:*\n",
    "\n",
    "    python tools/test.py configs/regnet/pointpillars_hv_regnet-400mf_secfpn_sbn-all_8xb4-2x_nus-3d.py  models/hv_pointpillars_regnet-400mf_secfpn_sbn-all_4x8_2x_nus-3d_20200620_230334-53044f32.pth  --cfg-options 'test_evaluator.jsonfile_prefix=./tmp'\n",
    "    \n",
    "    result file saved in: ~/pkl/result_objdet/SECFPN/\n",
    "    \n",
    "    mAP measured: 0.3489\n",
    "\n",
    "\n",
    "- SSN https://github.com/open-mmlab/mmdetection3d/tree/main/configs/ssn\n",
    "  - RegNetX-400MF-SSN hv_ssn_regnet-400mf_secfpn_sbn-all_2x16_2x_nus-3d_20210829_210615-361e5e04.pth\n",
    "  \n",
    "    *run using:*\n",
    "\n",
    "    python tools/test.py configs/ssn/ssn_hv_regnet-400mf_secfpn_sbn-all_16xb2-2x_nus-3d.py models/hv_ssn_regnet-400mf_secfpn_sbn-all_2x16_2x_nus-3d_20210829_210615-361e5e04.pth --cfg-options 'test_evaluator.jsonfile_prefix=./tmp'\n",
    "\n",
    "    result file saved in: ~/pkl/result_objdet/SSN/\n",
    "\n",
    "    mAP measured: 0.46\n",
    "  \n",
    "  \n",
    "- FCOS3D https://github.com/open-mmlab/mmdetection3d/tree/main/configs/fcos3d\n",
    "  - fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune_20210717_095645-8d806dc2.pth\n",
    "  \n",
    "    *run using:*\n",
    "\n",
    "    python tools/test.py configs/fcos3d/fcos3d_r101-caffe-dcn_fpn_head-gn_8xb2-1x_nus-mono3d_finetune.py  models/fcos3d_r101_caffe_fpn_gn-head_dcn_2x8_1x_nus-mono3d_finetune_20210717_095645-8d806dc2.pth  --cfg-options 'test_evaluator.jsonfile_prefix=./tmp'\n",
    "\n",
    "    result file saved in: ~/pkl/result_objdet/FCOS3d/\n",
    "\n",
    "    mAP measured: 0.32\n",
    "\n",
    "\n",
    "- pgd https://github.com/open-mmlab/mmdetection3d/tree/v1.0.0.dev0/configs/pgd\n",
    "  - pgd_r101_caffe_fpn_gn-head_2x16_2x_nus-mono3d_20211112_125314-cb677266.pth\n",
    "\n",
    "     *run using:*\n",
    "\n",
    "    python tools/test.py configs/pgd/pgd_r101-caffe_fpn_head-gn_16xb2-1x_nus-mono3d_finetune.py models/pgd_r101_caffe_fpn_gn-head_2x16_1x_nus-mono3d_finetune_20211118_093245-fd419681.pth  --cfg-options 'test_evaluator.jsonfile_prefix=./tmp'\n",
    "\n",
    "    result file saved in: ~/pkl/result_objdet/PGD/\n",
    "\n",
    "    mAP measured: 0.33\n",
    "    \n",
    " \n",
    "- pointpillars https://github.com/open-mmlab/mmdetection3d/tree/main/configs/pointpillars\n",
    "  - hv_pointpillars_fpn_sbn-all_fp16_2x8_2x_nus-3d_20201021_120719-269f9dd6.pth\n",
    " \n",
    "     *run using:*\n",
    "\n",
    "    python tools/test.py configs/pointpillars/pointpillars_hv_fpn_sbnpointpillars/pointpillars_hv_fpn_sbn-all_8xb2-amp-2x_nus-3d.py models/hv_pous-3d_20201021_120719-269f9dd6.pthintpillars_fpn_sbn-all_fp16_2x8_2x_nus-3d_20201021_120719-269f9dd6.pth   --cfg-options 'test_evaluator.jsonfile_prefix=./tmp'\n",
    "\n",
    "    result file saved in: ~/pkl/result_objdet/POINTP/\n",
    "\n",
    "    mAP measured: 0.35\n",
    "    \n",
    "\n",
    "- RegNetX-1.6gF-FPN https://github.com/open-mmlab/mmdetection3d/tree/main/configs/regnet\n",
    "  - hv_pointpillars_regnet-1.6gf_fpn_sbn-all_4x8_2x_nus-3d_20200629_050311-dcd4e090.pth \n",
    "  \n",
    "     *run using:*\n",
    "\n",
    "    python tools/test.py configs/regnet/pointpillars_hv_regnet-1.6gf_fpn_sbn-all_8xb4-2x_nus-3d.py models/hv_pointpillars_regnet-1.6gf_fpn_sbn-all_4x8_2x_nus-3d_20200629_050311-dcd4e090.pth  --cfg-options 'test_evaluator.jsonfile_prefix=./tmp1'\n",
    "\n",
    "    result file saved in: ~/pkl/result_objdet/REG/\n",
    "\n",
    "    mAP measured: 0.44\n",
    "    \n",
    "\n",
    "- NOT IMPLEMENTED YET BEVFusion https://github.com/open-mmlab/mmdetection3d/tree/dev-1.x/projects/BEVFusion\n",
    "  - lidar bevfusion_lidar_voxel0075_second_secfpn_8xb4-cyclic-20e_nus-3d-2628f933.pth\n",
    "\n",
    "\n",
    "-  NOT IMPLEMENTED YET  DETR3D https://github.com/open-mmlab/mmdetection3d/tree/dev-1.x/projects/DETR3D\n",
    "  - DETR3D, detr3d_r101_gridmask.pth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3bfeea",
   "metadata": {},
   "source": [
    "**Now the following code realizes our GOALs**\n",
    "\n",
    "**Note1:** it takes several days to execute. It is strongly recommended to divide the execution in shorter runs.\n",
    "\n",
    "**Note2:** for GOAL1, it is OK to run this and that's all. For GOAL2, it is recommended to run with selected settings. This will save lots of time. Then with the preferred settings, you can do detailed investigations using the other jupyter notebook we provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "044e74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import unittest\n",
    "import sklearn\n",
    "import tqdm\n",
    "import pandas\n",
    "import math\n",
    "import json\n",
    "from typing import Callable\n",
    "from nuscenes import NuScenes\n",
    "from nuscenes.eval.prediction.splits import *\n",
    "import nuscenes.eval.detection.config as cnfig\n",
    "from nuscenes.eval.detection.configs import *\n",
    "from nuscenes.eval.detection.data_classes import DetectionBox \n",
    "from nuscenes.eval.detection import *\n",
    "import nuscenes.eval.detection.algo as ag\n",
    "from nuscenes.eval.detection.data_classes import DetectionMetricData, DetectionConfig, DetectionMetrics, DetectionBox, \\\n",
    "    DetectionMetricDataList\n",
    "from nuscenes.eval.common.data_classes import EvalBoxes\n",
    "from typing import List, Dict, Callable, Tuple\n",
    "from nuscenes.eval.common.utils import center_distance, scale_iou, yaw_diff, velocity_l2, attr_acc, cummean\n",
    "import nuscenes.eval.detection.evaluate as dcl    \n",
    "from nuscenes.prediction import *\n",
    "from nuscenes.map_expansion.map_api import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "432b39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pyquaternion import Quaternion\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "\n",
    "from pkl.models import compile_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924fd8be",
   "metadata": {},
   "source": [
    "**Debugging parameters** , set both to False if you are doing the long run.\n",
    "\n",
    "If test = True, it only runs few combinations. Good to have a first understanding of what happens.\n",
    "\n",
    "If verbose = True, it prints many things and do more checks. Will take much more time to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7653bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=False #does reduced runs, with fewer parameters\n",
    "verbose=False #avoid so much printing, checks, elaborations, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb37cf01",
   "metadata": {},
   "source": [
    "**Configuration items**\n",
    "\n",
    "Configuration parameters. Rather intuitive: \n",
    "\n",
    "* set the GOAL you want (see the paper)\n",
    "*  decide if you want only cars or all objects\n",
    "* and set the paths to the correct folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36198fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOAL=\"GOAL2\" #set GOAL2, GOAL3, GOAL4 depending what to evaluate\n",
    "\n",
    "car_only=False #filters out all non-car objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece0241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(GOAL==\"GOAL1\"): # GOAL1 configs\n",
    "    #the classes we consider. We can create \"set of objects\". It accepts 2 sets of objects.\n",
    "    #however we have a criticality model only for cars -- so do not remove cars from the list\n",
    "    #TODO WE NEED CURRENTLY TO EXECUTE EVERYTHING TWICE; THE object_classes_reduced does nothing\n",
    "    if test:\n",
    "        object_classes=['car', 'truck', 'bus', 'trailer', 'construction_vehicle', 'pedestrian', 'motorcycle', 'bicycle', 'traffic_cone', 'barrier']    \n",
    "        object_classes_reduced=['car']\n",
    "    else:    \n",
    "        object_classes=['car', 'truck', 'bus', 'trailer', 'construction_vehicle', 'pedestrian', 'motorcycle', 'bicycle', 'traffic_cone', 'barrier']    \n",
    "        object_classes_reduced=['car']\n",
    "\n",
    "    if car_only:\n",
    "        object_classes=object_classes_reduced\n",
    "\n",
    "    if test:\n",
    "    #distance, intersect, time from our marvellous solution. \n",
    "        MAX_D=[15, 20,  25]\n",
    "        MAX_R=[15, 20,  25]\n",
    "        MAX_T=[12, 16, 20]\n",
    "    else:\n",
    "    #distance, intersect, time from our marvellous solution. \n",
    "        MAX_D=list(range(10, 55, 10))\n",
    "        MAX_R=list(range(10, 55, 10))\n",
    "        MAX_T=list(range(16, 25, 4))\n",
    "#        MAX_D=list(range(5, 35, 5))\n",
    "#        MAX_R=list(range(5, 35, 5))\n",
    "#        MAX_T=list(range(4, 22, 4))\n",
    "\n",
    "    #distance_intersect_time combinations\n",
    "    DRT = list(itertools.product(*[MAX_D, MAX_R, MAX_T]))\n",
    "\n",
    "    #the 4 distances for evaluation\n",
    "    if test: #but it is essentially useless to reduce here\n",
    "        dist=[0.5, 1.0, 2.0, 4.0]\n",
    "    else:\n",
    "        dist=[0.5, 1.0, 2.0, 4.0]\n",
    "\n",
    "    #the confidence thresholds for the pkl\n",
    "    if test:\n",
    "        CONF_TH= [0.4, 0.45, 0.5]\n",
    "    else:\n",
    "        CONF_TH=list(np.arange(0.05, 0.4, 0.05))\n",
    "#        CONF_TH=list(np.arange(0.4, 0.6, 0.05))\n",
    "\n",
    "    #the criticalities thresholds of the pkl\n",
    "    if test:\n",
    "        criticalities=[ 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "    else:\n",
    "        criticalities=list(np.arange(0.10, 0.4, 0.05))\n",
    "#        criticalities=list(np.arange(0.3, 0.7, 0.05))\n",
    "\n",
    "if (GOAL=='GOAL2'):\n",
    "    if test:\n",
    "        object_classes=['car', 'truck', 'bus', 'trailer', 'construction_vehicle', 'pedestrian', 'motorcycle', 'bicycle', 'traffic_cone', 'barrier']    \n",
    "        object_classes_reduced=['car']\n",
    "    else:    \n",
    "        object_classes=['car', 'truck', 'bus', 'trailer', 'construction_vehicle', 'pedestrian', 'motorcycle', 'bicycle', 'traffic_cone', 'barrier']    \n",
    "        object_classes_reduced=['car']\n",
    "\n",
    "    if car_only:\n",
    "        object_classes=object_classes_reduced\n",
    "\n",
    "    if test:\n",
    "    #distance, intersect, time from our marvellous solution. \n",
    "        MAX_D=[15, 20,  25]\n",
    "        MAX_R=[15, 20,  25]\n",
    "        MAX_T=[12, 16, 20]\n",
    "    else:\n",
    "    #distance, intersect, time from our marvellous solution. \n",
    "        MAX_D=list(range(40, 55, 5))\n",
    "        MAX_R=list(range(40, 55, 5))\n",
    "        MAX_T=list(range(40, 41, 4))\n",
    "\n",
    "    #distance_intersect_time combinations\n",
    "    DRT = list(itertools.product(*[MAX_D, MAX_R, MAX_T]))\n",
    "\n",
    "    #the 4 distances for evaluation\n",
    "    if test: #but it is essentially useless to reduce here\n",
    "        dist=[0.5, 1.0, 2.0, 4.0]\n",
    "    else:\n",
    "        dist=[0.5, 1.0, 2.0, 4.0]\n",
    "\n",
    "    #the confidence thresholds for the pkl\n",
    "    if test:\n",
    "        CONF_TH= [0.4, 0.5]\n",
    "    else:\n",
    "        CONF_TH=list(np.arange(0.35, 0.45, 0.05))\n",
    "\n",
    "    #the criticalities thresholds of the pkl\n",
    "    if test:\n",
    "        criticalities=[ 0.7, 0.9]\n",
    "    else:\n",
    "        criticalities=[0.3, 0.4, 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63517d8",
   "metadata": {},
   "source": [
    "system and output configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db9ff464",
   "metadata": {},
   "outputs": [],
   "source": [
    "nworkers=10 # number of workers for dataloader: depends on your resources!\n",
    "bsz= 128# batch size for dataloader: depends on your resources!\n",
    "gpuid=0 #id of the gpu; -1 if no GPU\n",
    "\n",
    "#base path for the notebook (home directory)\n",
    "NOTEBOOK_HOME='/home/notebook/'\n",
    "    \n",
    "#nuscene dataset install folder\n",
    "DATAROOT=NOTEBOOK_HOME+'nuscene/data'\n",
    "\n",
    "#pkl path to planner.pt and masks_trainval.json\n",
    "modelpath=NOTEBOOK_HOME+'pkl/Evaluation-Of-Safety-Oriented-Metrics-for-Object-Detectors/metrics_model/planner.pt'\n",
    "mask_json=NOTEBOOK_HOME+'pkl/Evaluation-Of-Safety-Oriented-Metrics-for-Object-Detectors/metrics_model/masks_trainval.json'\n",
    "\n",
    "#results of the object detectors (result_nusc.json) are stored here, in subdirectories:\n",
    "#PATH+DETECTOR+FILE_JSON\n",
    "#e.g. '/home/notebook/pkl/result_objdet/PGD/results_nusc.json'\n",
    "PATH=NOTEBOOK_HOME+'pkl/result_objdet/'\n",
    "FILE_JSON='/results_nusc.json'\n",
    "\n",
    "#results computed are stored here. Subfolders will be created, like:\n",
    "#/home/notebook/pkl/results/PGD/'\n",
    "RESULTS_PATH=NOTEBOOK_HOME+'pkl/results/GOAL2/'\n",
    "\n",
    "#how many images in bird view you want to draw\n",
    "NUMBER_IMAGE=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea9145",
   "metadata": {},
   "source": [
    "Should not be touched. If test is False, will take days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da926391",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test:\n",
    "    DETECTOR= {\"PointPillars\": 'POINTP',}\n",
    "else:\n",
    "    #the object detector that were experimented on nuscenes\n",
    "    DETECTOR= {#\"RegNetX-1.6gF-FPN\":'REG',\n",
    "            #\"SECFPN\": 'SECFPN',\n",
    "            #\"PointPillars\": 'POINTP',\n",
    "            \"SSN\": 'SSN',\n",
    "#            \"PGD\": 'PGD',\n",
    "#            \"FCOS3D\": 'FCOS3D',\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621cd19a",
   "metadata": {},
   "source": [
    "Following is whole code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89a3dcbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "Loading NuScenes tables for version v1.0-trainval...\n",
      "23 category,\n",
      "8 attribute,\n",
      "4 visibility,\n",
      "64386 instance,\n",
      "12 sensor,\n",
      "10200 calibrated_sensor,\n",
      "2631083 ego_pose,\n",
      "68 log,\n",
      "850 scene,\n",
      "34149 sample,\n",
      "2631083 sample_data,\n",
      "1166187 sample_annotation,\n",
      "4 map,\n",
      "Done loading in 27.039 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 7.0 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "nuscenes = NuScenes('v1.0-trainval', dataroot=DATAROOT)\n",
    "confvalue=cnfig.config_factory(\"detection_cvpr_2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1685adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of scene that compose the val set\n",
    "if test:\n",
    "    eval=val =['scene-0519','scene-0013',]\n",
    "\n",
    "else:\n",
    "    eval=val = ['scene-0013',\n",
    "                'scene-0554',\n",
    "                'scene-0771',\n",
    "                'scene-0929',\n",
    "                'scene-1070',\n",
    "                'scene-1072',\n",
    "                'scene-0798',\n",
    "                'scene-0108',\n",
    "                'scene-0519',\n",
    "                'scene-0332',\n",
    "               ]\n",
    "'''\n",
    "        ['scene-0003', 'scene-0012', 'scene-0013', 'scene-0014', 'scene-0015', 'scene-0016', 'scene-0017', 'scene-0018',\n",
    "         'scene-0035', 'scene-0036', 'scene-0038', 'scene-0039', 'scene-0092', 'scene-0093', 'scene-0094', 'scene-0095',\n",
    "         'scene-0096', 'scene-0097', 'scene-0098', 'scene-0099', 'scene-0100', 'scene-0101', 'scene-0102', 'scene-0103',\n",
    "         'scene-0104', 'scene-0105', 'scene-0106', 'scene-0107', 'scene-0108', 'scene-0109', 'scene-0110', 'scene-0221',\n",
    "         'scene-0268', 'scene-0269', 'scene-0270', 'scene-0271', 'scene-0272', 'scene-0273', 'scene-0274', 'scene-0275',\n",
    "         'scene-0276', 'scene-0277', 'scene-0278', 'scene-0329', 'scene-0330', 'scene-0331', 'scene-0332', 'scene-0344',\n",
    "         'scene-0345', 'scene-0346', 'scene-0519', 'scene-0520', 'scene-0521', 'scene-0522', 'scene-0523', 'scene-0524',\n",
    "         'scene-0552', 'scene-0553', 'scene-0554', 'scene-0555', 'scene-0556', 'scene-0557', 'scene-0558', 'scene-0559',\n",
    "         'scene-0560', 'scene-0561', 'scene-0562', 'scene-0563', 'scene-0564', 'scene-0565', 'scene-0625', 'scene-0626',\n",
    "         'scene-0627', 'scene-0629', 'scene-0630', 'scene-0632', 'scene-0633', 'scene-0634', 'scene-0635', 'scene-0636',\n",
    "         'scene-0637', 'scene-0638', 'scene-0770', 'scene-0771', 'scene-0775', 'scene-0777', 'scene-0778', 'scene-0780',\n",
    "         'scene-0781', 'scene-0782', 'scene-0783', 'scene-0784', 'scene-0794', 'scene-0795', 'scene-0796', 'scene-0797',\n",
    "         'scene-0798', 'scene-0799', 'scene-0800', 'scene-0802', 'scene-0904', 'scene-0905', 'scene-0906', 'scene-0907',\n",
    "         'scene-0908', 'scene-0909', 'scene-0910', 'scene-0911', 'scene-0912', 'scene-0913', 'scene-0914', 'scene-0915',\n",
    "         'scene-0916', 'scene-0917', 'scene-0919', 'scene-0920', 'scene-0921', 'scene-0922', 'scene-0923', 'scene-0924',\n",
    "         'scene-0925', 'scene-0926', 'scene-0927', 'scene-0928', 'scene-0929', 'scene-0930', 'scene-0931', 'scene-0962',\n",
    "         'scene-0963', 'scene-0966', 'scene-0967', 'scene-0968', 'scene-0969', 'scene-0971', 'scene-0972', 'scene-1059',\n",
    "         'scene-1060', 'scene-1061', 'scene-1062', 'scene-1063', 'scene-1064', 'scene-1065', 'scene-1066', 'scene-1067',\n",
    "         'scene-1068', 'scene-1069', 'scene-1070', 'scene-1071', 'scene-1072', 'scene-1073']\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9351875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e35a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the list of tokens in the val set (150 scenes), put it in a file to be used as input\n",
    "scenes_list=[]\n",
    "counter=0\n",
    "\n",
    "for i in nuscenes.scene:\n",
    "    name=i['name']\n",
    "    if(name in val):\n",
    "        counter=counter+1\n",
    "        scenes_list.append(i)\n",
    "\n",
    "validation_samples={}\n",
    "for i in scenes_list:\n",
    "    scene_name=i['name']\n",
    "    sample_token_list=[]\n",
    "    first_sample_token=i['first_sample_token']\n",
    "    last_sample_token=i['last_sample_token']\n",
    "    current_sample_token=first_sample_token\n",
    "    sample_token_list.append(current_sample_token)\n",
    "    if(sample_token_list[0]!=first_sample_token):\n",
    "        print(\"error\")\n",
    "        break\n",
    "    while(current_sample_token!=last_sample_token):\n",
    "        sample=nuscenes.get('sample', current_sample_token)\n",
    "        current_sample_token=sample['next']\n",
    "        sample_token_list.append(current_sample_token)\n",
    "    if(sample_token_list[len(sample_token_list)-1]!=last_sample_token):\n",
    "        print(\"error\")\n",
    "        break\n",
    "    \n",
    "    validation_samples.update({scene_name:sample_token_list})\n",
    "\n",
    "listtoken=[]\n",
    "for i in validation_samples.keys():\n",
    "    listtoken.extend(validation_samples[i])\n",
    "\n",
    "with open(RESULTS_PATH+\"/token_list.json\", \"w\") as outfile: \n",
    "    json.dump(validation_samples, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cb51123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dt(detector_file=\"none\",\n",
    "              val='val',\n",
    "              model='none',\n",
    "              d=1,\n",
    "              r=1,\n",
    "              t=1,\n",
    "              verbose=False,\n",
    "              recall_type=\"PRED AL NUMERATORE\",\n",
    "              nworkers=10, #for pkl\n",
    "              bsz= 128, #for pkl\n",
    "              gpuid=0# GPU ID, -1 if CPU only\n",
    "             ):\n",
    "\n",
    "    \n",
    "    dt=dcl.DetectionEval(nusc=nuscenes,\n",
    "        config=confvalue,\n",
    "        result_path=detector_file,\n",
    "        eval_set=val,\n",
    "        model_name=model,\n",
    "        MAX_DISTANCE_OBJ=d,\n",
    "        MAX_DISTANCE_INTERSECT=r,\n",
    "        MAX_TIME_INTERSECT_OBJ=t,\n",
    "        verbose=verbose,\n",
    "        recall_type=\"PRED AL NUMERATORE\",\n",
    "        nworkers=nworkers,\n",
    "        bsz=bsz,\n",
    "        gpuid=gpuid,\n",
    "        )\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b95ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_crit_pkl(dt,\n",
    "                     listtoken=[],\n",
    "                     conf_th_list=[0.4],\n",
    "                     dist_list=[2.0],\n",
    "                     crit_list=[0.5],\n",
    "                     object_classes='car',\n",
    "                     verbose=False,\n",
    "                     model_loaded=False,#an attempt to load the model outside the pkl\n",
    "                     model_object=None):\n",
    "\n",
    "    results= dt.safety_metric_evaluation(\n",
    "                    list_of_tokens=listtoken,\n",
    "                    conf_th_list=conf_th_list,\n",
    "                    dist_list=dist_list,\n",
    "                    crit_list=criticalities,\n",
    "                    obj_classes_list=object_classes, \n",
    "                    render_images=False,\n",
    "                    verbose=verbose,\n",
    "                    model_loaded=True,#an attempt to load the model outside the pkl\n",
    "                    model_object=model_object,\n",
    "                    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2145f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_crit_pkl_GOAL2(dt,\n",
    "                     listtoken=[],\n",
    "                     conf_th_list=[0.4],\n",
    "                     dist_list=[2.0],\n",
    "                     crit_list=[0.5],\n",
    "                     object_classes='car',\n",
    "                     verbose=False,\n",
    "                     model_loaded=False,#an attempt to load the model outside the pkl\n",
    "                     model_object=None):\n",
    "\n",
    "    results= dt.safety_metric_evaluation_GOAL2(\n",
    "                    list_of_tokens=listtoken,\n",
    "                    conf_th_list=conf_th_list,\n",
    "                    dist_list=dist_list,\n",
    "                    crit_list=criticalities,\n",
    "                    obj_classes_list=object_classes, \n",
    "                    render_images=False,\n",
    "                    verbose=verbose,\n",
    "                    model_loaded=model_loaded,#an attempt to load the model outside the pkl\n",
    "                    model_object=model_object,\n",
    "                    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c520a8",
   "metadata": {},
   "source": [
    "load pkl model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a778daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notebook/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/notebook/anaconda3/envs/openmmlab/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# constants related to how the planner was trained\n",
    "layer_names = ['road_segment', 'lane']\n",
    "line_names = ['road_divider', 'lane_divider']\n",
    "stretch = 70.0\n",
    "\n",
    "device = torch.device(f'cuda:0')\n",
    "\n",
    "# load planner\n",
    "model = compile_model(cin=5, cout=16, with_skip=True,\n",
    "                          dropout_p=0.0).to(device)\n",
    "\n",
    "if not os.path.isfile(modelpath):\n",
    "    print(f'downloading model weights to location {modelpath}...')\n",
    "    cmd = f\"wget --quiet --no-check-certificate 'https://docs.google.com/uc?export=download&id=1feEIUjYSNWkl_b5SUkmPZ_-JAj3licJ9' -O {modelpath}\"\n",
    "    print(f'running {cmd}')\n",
    "    os.system(cmd)\n",
    "    print(f'using model weights {modelpath}')\n",
    "\n",
    "model.load_state_dict(torch.load(modelpath, map_location=torch.device('cpu')))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# load masks\n",
    "if not os.path.isfile(mask_json):\n",
    "    print(f'downloading model masks to location {mask_json}...')\n",
    "    cmd = f\"wget --quiet --no-check-certificate 'https://docs.google.com/uc?export=download&id=13M1xj9MkGo583ok9z8EkjQKSV8I2nWWF' -O {mask_json}\"\n",
    "    print(f'running {cmd}')\n",
    "    os.system(cmd)\n",
    "    if verbose:\n",
    "        print(f'using location masks {mask_json}')\n",
    "with open(mask_json, 'r') as reader:\n",
    "    masks = (torch.Tensor(json.load(reader)) == 1).to(device)\n",
    "\n",
    "model_object=[model, masks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eafeff",
   "metadata": {},
   "source": [
    "**GOAL 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5621b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_list=dist\n",
    "#iterate on all detectors (SSN, POINTPILLARS, ...)\n",
    "for detector_name, folder in DETECTOR.items():\n",
    "    if (GOAL!=\"GOAL1\"):#just a bad trick to avoid this code if GOAL1 is not the target\n",
    "        continue\n",
    "    pkl_results_store=[]\n",
    "    pkl_crit_results_store=[]\n",
    "    ap_results_store=[]\n",
    "    print(detector_name, folder)\n",
    "    #path + json file where detection results from mmdetection3d are stored, ready to be processed\n",
    "    detector_file=PATH+folder+FILE_JSON\n",
    "    #results of evaluation will be stored here\n",
    "    output_folder='/home/notebook/pkl/results/'+folder+\"/\"\n",
    "    if not os.path.exists(output_folder): \n",
    "        os.makedirs(output_folder) \n",
    "    #iterate on drt\n",
    "    for d, r, t  in DRT:\n",
    "        print(\"DRT tuple is {}, {}, {}\".format(d, r, t))\n",
    "        print(\"Loading dt\")\n",
    "        dt=create_dt(detector_file,\n",
    "                     'val',\n",
    "                     model=detector_name,\n",
    "                     d=d,\n",
    "                     r=r,\n",
    "                     t=t,\n",
    "                     verbose=verbose,\n",
    "                     recall_type=\"PRED AL NUMERATORE\")\n",
    "        #compute ap, ap_crit, and pkl, varying dist, confth\n",
    "        print(\"Now evaluating object_classes {}\".format(object_classes))\n",
    "        ap_results, pkl_results, pkl_crit_results=compute_crit_pkl(dt=dt,\n",
    "                     listtoken=listtoken,\n",
    "                     conf_th_list=CONF_TH,\n",
    "                     dist_list=dist_list,\n",
    "                     crit_list=criticalities,\n",
    "                     object_classes=object_classes,#filter boxes based on class\n",
    "                     verbose=verbose,\n",
    "                     model_loaded=True,#an attempt to load the model outside the pkl\n",
    "                     model_object=model_object)\n",
    "\n",
    "        #storing values for later printing in json file\n",
    "        ap_results.update({\"DRT\": {\"D\": d, \"R\": r, \"T\": t}})\n",
    "        ap_results_store.append(ap_results)\n",
    "        pkl_results_store.append(pkl_results)\n",
    "        pkl_crit_results_store.append(pkl_crit_results)\n",
    "\n",
    "        with open(output_folder+'ap_results.json', 'w') as f:\n",
    "            json.dump({\"AP_RESULTS\": ap_results_store}, f)\n",
    "        \n",
    "        with open(output_folder+'pkl_results.json', 'w') as f:\n",
    "            json.dump({\"PKL_RESULTS\": pkl_results_store}, f)\n",
    "\n",
    "        with open(output_folder+'pkl_crit_results_GOAL1.json', 'w') as f:\n",
    "            json.dump({\"PKL_CRIT_RESULTS\": pkl_crit_results_store}, f)\n",
    "\n",
    "        print(\"ONE FULL ROUND COMPLETED! drt= {}, model={}\".format((d,r, t), detector_name))\n",
    "        dt=None\n",
    "\n",
    "    with open(output_folder+'ap_results.json', 'w') as f:\n",
    "        json.dump({\"AP_RESULTS\": ap_results_store}, f)\n",
    "\n",
    "    with open(output_folder+'pkl_results.json', 'w') as f:\n",
    "        json.dump({\"PKL_RESULTS\": pkl_results_store}, f)\n",
    "\n",
    "    with open(output_folder+'pkl_crit_results_GOAL1.json', 'w') as f:\n",
    "        json.dump({\"PKL_CRIT_RESULTS\": pkl_crit_results_store}, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e022d",
   "metadata": {},
   "source": [
    "**GOAL 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1e18642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRT tuple is 40, 40, 40\n",
      "Loading dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating object_classes ['car', 'truck', 'bus', 'trailer', 'construction_vehicle', 'pedestrian', 'motorcycle', 'bicycle', 'traffic_cone', 'barrier']\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "ONE FULL ROUND COMPLETED! drt= (40, 40, 40), model=SSN\n",
      "DRT tuple is 40, 45, 40\n",
      "Loading dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating object_classes ['car', 'truck', 'bus', 'trailer', 'construction_vehicle', 'pedestrian', 'motorcycle', 'bicycle', 'traffic_cone', 'barrier']\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "ONE FULL ROUND COMPLETED! drt= (40, 45, 40), model=SSN\n",
      "DRT tuple is 40, 50, 40\n",
      "Loading dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating object_classes ['car', 'truck', 'bus', 'trailer', 'construction_vehicle', 'pedestrian', 'motorcycle', 'bicycle', 'traffic_cone', 'barrier']\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "ONE FULL ROUND COMPLETED! drt= (40, 50, 40), model=SSN\n",
      "DRT tuple is 45, 40, 40\n",
      "Loading dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating object_classes ['car', 'truck', 'bus', 'trailer', 'construction_vehicle', 'pedestrian', 'motorcycle', 'bicycle', 'traffic_cone', 'barrier']\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "ONE FULL ROUND COMPLETED! drt= (45, 40, 40), model=SSN\n",
      "DRT tuple is 45, 45, 40\n",
      "Loading dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating object_classes ['car', 'truck', 'bus', 'trailer', 'construction_vehicle', 'pedestrian', 'motorcycle', 'bicycle', 'traffic_cone', 'barrier']\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "ONE FULL ROUND COMPLETED! drt= (45, 45, 40), model=SSN\n",
      "DRT tuple is 45, 50, 40\n",
      "Loading dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating object_classes ['car', 'truck', 'bus', 'trailer', 'construction_vehicle', 'pedestrian', 'motorcycle', 'bicycle', 'traffic_cone', 'barrier']\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "ONE FULL ROUND COMPLETED! drt= (45, 50, 40), model=SSN\n",
      "DRT tuple is 50, 40, 40\n",
      "Loading dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating object_classes ['car', 'truck', 'bus', 'trailer', 'construction_vehicle', 'pedestrian', 'motorcycle', 'bicycle', 'traffic_cone', 'barrier']\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "ONE FULL ROUND COMPLETED! drt= (50, 40, 40), model=SSN\n",
      "DRT tuple is 50, 45, 40\n",
      "Loading dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating object_classes ['car', 'truck', 'bus', 'trailer', 'construction_vehicle', 'pedestrian', 'motorcycle', 'bicycle', 'traffic_cone', 'barrier']\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "ONE FULL ROUND COMPLETED! drt= (50, 45, 40), model=SSN\n",
      "DRT tuple is 50, 50, 40\n",
      "Loading dt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now evaluating object_classes ['car', 'truck', 'bus', 'trailer', 'construction_vehicle', 'pedestrian', 'motorcycle', 'bicycle', 'traffic_cone', 'barrier']\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "pkls computed with output of size : 403\n",
      "ONE FULL ROUND COMPLETED! drt= (50, 50, 40), model=SSN\n"
     ]
    }
   ],
   "source": [
    "dist_list=dist\n",
    "#iterate on all detectors (SSN, POINTPILLARS, ...)\n",
    "for detector_name, folder in DETECTOR.items():\n",
    "    if (GOAL!=\"GOAL2\"):#just a bad trick to avoid this code if GOAL2 is not the target\n",
    "        continue\n",
    "    pkl_crit_results_store=[]\n",
    "    #path + json file where detection results from mmdetection3d are stored, ready to be processed\n",
    "    detector_file=PATH+folder+FILE_JSON\n",
    "    #results of evaluation will be stored here\n",
    "    output_folder='/home/notebook/pkl/results/GOAL2/'+folder+\"/\"\n",
    "    if not os.path.exists(output_folder): \n",
    "        os.makedirs(output_folder) \n",
    "    #iterate on drt\n",
    "    for d, r, t  in DRT:\n",
    "        print(\"DRT tuple is {}, {}, {}\".format(d, r, t))\n",
    "        print(\"Loading dt\")\n",
    "        dt=create_dt(detector_file,\n",
    "                     'val',\n",
    "                     model=detector_name,\n",
    "                     d=d,\n",
    "                     r=r,\n",
    "                     t=t,\n",
    "                     verbose=verbose,\n",
    "                     recall_type=\"PRED AL NUMERATORE\")\n",
    "        #compute ap, ap_crit, and pkl, varying dist, confth\n",
    "        print(\"Now evaluating object_classes {}\".format(object_classes))\n",
    "        pkl_crit_results=compute_crit_pkl_GOAL2(dt=dt,\n",
    "                                 listtoken=listtoken,\n",
    "                                 conf_th_list=CONF_TH,\n",
    "                                 dist_list=dist_list,\n",
    "                                 crit_list=criticalities,\n",
    "                                 object_classes=object_classes,#filter boxes based on class\n",
    "                                 verbose=verbose,\n",
    "                                 model_loaded=True,#an attempt to load the model outside the pkl\n",
    "                                 model_object=model_object)\n",
    "\n",
    "        #storing values for later printing in json file\n",
    "        pkl_crit_results_store.append(pkl_crit_results)\n",
    "\n",
    "        with open(output_folder+'pkl_crit_results_GOAL2.json', 'w') as f:\n",
    "            json.dump({\"PKL_CRIT_RESULTS_GOAL2\": pkl_crit_results_store}, f)\n",
    "\n",
    "        print(\"ONE FULL ROUND COMPLETED! drt= {}, model={}\".format((d,r, t), detector_name))\n",
    "        dt=None\n",
    "\n",
    "#    with open(output_folder+'ap_results.json', 'w') as f:\n",
    "#        json.dump({\"AP_RESULTS\": ap_results_store}, f)\n",
    "\n",
    "#    with open(output_folder+'pkl_results.json', 'w') as f:\n",
    "#        json.dump({\"PKL_RESULTS\": pkl_results_store}, f)\n",
    "\n",
    "    with open(output_folder+'pkl_crit_results_GOAL2.json', 'w') as f:\n",
    "        json.dump({\"PKL_CRIT_RESULTS_GOAL2\": pkl_crit_results_store}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1f7141",
   "metadata": {},
   "source": [
    "**GOAL 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c8c52",
   "metadata": {},
   "source": [
    "See dedicated notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bbae0c",
   "metadata": {},
   "source": [
    "**GOAL 4**\n",
    "\n",
    "Implementation not needed. \n",
    "\n",
    "Just run everything with all the detectors, and move to the notebook that analyze results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "openmmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
